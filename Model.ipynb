{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import nltk\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Conv1D, Dot, Bidirectional, Flatten\n",
    "from IPython.display import display, HTML # to display in ipython notebook\n",
    "import matplotlib.cm\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOV_TOKEN = '<UNK>'\n",
    "EPOCHS = 2\n",
    "PADDED_LEN = 100\n",
    "BATCH_SIZE = 32\n",
    "N_SAMPLES = 500000\n",
    "N_CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and preprocess text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the prebuilt vocabulary list from a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    vocab_list = pickle.load(f)\n",
    "    word_counts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class that is responsible for tokenizing and encoding sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerEncoder:\n",
    "    def __init__(self, vocab_list, oov_token, lower=True, \n",
    "                 filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r'):\n",
    "        self.word_index = {word:(index+2) for index, word in enumerate(vocab_list)} # index 0 is reserved for padding token\n",
    "                                                                                    # index 1 is reserved for out of vocab token\n",
    "        self.word_index[oov_token] = 1\n",
    "        \n",
    "        self.reverse_word_index = {v: k for k, v in self.word_index.items()}\n",
    "        self.reverse_word_index[0] = '' # for decoding\n",
    "        \n",
    "        self.oov_token = oov_token\n",
    "        self.lower = lower\n",
    "        self.filters = filters\n",
    "        \n",
    "    def encode(self, text):\n",
    "        # tokenize\n",
    "        if self.lower:\n",
    "            text = text.lower() # convert to lowercase\n",
    "        text = text.translate(str.maketrans(self.filters, ' ' * len(self.filters))) # replace chars in filters with blank space\n",
    "        tokens = nltk.word_tokenize(text) # split text line into tokens\n",
    "        \n",
    "        # encode\n",
    "        encoded_tokens = [self.word_index[token] if token in self.word_index \n",
    "                          else self.word_index[self.oov_token] for token in tokens]\n",
    "        return encoded_tokens\n",
    "    \n",
    "    def decode(self, encoded_tokens):\n",
    "        tokens = [self.reverse_word_index[idx] for idx in encoded_tokens]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to transform the tensorflow `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TokenizerEncoder(vocab_list=vocab_list, oov_token=OOV_TOKEN)\n",
    "\n",
    "def tf_encode(text, stars):\n",
    "    \"\"\"Tokenize the texts and one-hot encode the labels\"\"\"\n",
    "    tf_text, tf_stars = tf.py_function(\n",
    "        # Use .numpy() to convert EagerTensors to their values\n",
    "        # Use .decode() to convert bytes to string\n",
    "        # Use tf.cast() to cast a tensor to a new type (from tf.float32 to tf.int64 in this case)\n",
    "        func=lambda text, stars: (tokenizer.encode(text.numpy().decode('utf-8')), \n",
    "                                  tf.one_hot(tf.cast(stars - 1.0, tf.int64), N_CLASSES)), \n",
    "        inp=[text, stars],\n",
    "        Tout=(tf.int64, tf.float32)\n",
    "    )\n",
    "    return tf_text, tf_stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.experimental.CsvDataset(os.path.join('data', 'reviews.csv'), \n",
    "                                          [tf.float32, tf.string], \n",
    "                                          header=True)\n",
    "dataset = dataset.map(lambda stars, text: (text, stars))\n",
    "dataset = dataset.map(tf_encode)\n",
    "dataset = dataset.map(lambda text, stars: (text[:PADDED_LEN], stars)) # truncate sequences longer than PADDED_LEN\n",
    "dataset = dataset.shuffle(buffer_size=5000)\n",
    "dataset = dataset.padded_batch(batch_size=BATCH_SIZE, padded_shapes=([PADDED_LEN], [None]))\n",
    "dataset = dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab_list) + 2 # 1 for padding token (zero), 1 for out-of-vocabulary token\n",
    "EMBED_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(inputs, d_a, r): # inputs H shape (None, PADDED_LEN, 2*u)\n",
    "    L = Conv1D(filters=d_a, \n",
    "               kernel_size=1, \n",
    "               activation='tanh', \n",
    "               padding='same')(inputs) # equivalent to matrix multiplication L = tanh(W_s1 * H), L shape (None, PADDED_LEN, d_a)\n",
    "    A = tf.nn.softmax(Conv1D(filters=r, \n",
    "                             kernel_size=1, \n",
    "                             activation='linear', \n",
    "                             padding='same')(L), \n",
    "                      axis=1, name='attention_weights') # A shape (None, PADDED_LEN, r)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0815 14:22:24.506874 11588 deprecation.py:506] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0815 14:22:24.539672 11588 deprecation.py:506] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0815 14:22:24.541020 11588 deprecation.py:506] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0815 14:22:24.542019 11588 deprecation.py:506] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(PADDED_LEN,)) # (None, PADDED_LEN)\n",
    "embed = Embedding(input_dim=VOCAB_SIZE, \n",
    "                  output_dim=EMBED_SIZE, \n",
    "                  embeddings_initializer='glorot_uniform', \n",
    "                  mask_zero=False)(inp) # (None, PADDED_LEN, EMBED_SIZE)\n",
    "bi_lstm = Bidirectional(LSTM(units=300, return_sequences=True))(embed) # (None, PADDED_LEN, 2*u)\n",
    "attention = attention_block(bi_lstm, d_a=350, r=30) # (None, PADDED_LEN, r)\n",
    "sentence_embedding = Dot(axes=[1, 1])([attention, bi_lstm]) # M = tranpose(A) * H, shape (None, r, 2*u)\n",
    "flatten = Flatten()(sentence_embedding) # (None, r * 2u)\n",
    "fc1 = Dense(units=3000, activation='relu')(flatten)\n",
    "fc2 = Dense(units=3000, activation='relu')(fc1)\n",
    "out = Dense(units=N_CLASSES, activation='softmax')(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 100)     1000200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 100, 600)     962400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 100, 350)     210350      bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 100, 30)      10530       conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose (TensorFl [(None, 30, 100)]    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorFlow [(None, 30, 100)]    0           tf_op_layer_transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_attention_weights ( [(None, 100, 30)]    0           tf_op_layer_Softmax[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 30, 600)      0           tf_op_layer_attention_weights[0][\n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 18000)        0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3000)         54003000    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3000)         9003000     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            15005       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 65,204,485\n",
      "Trainable params: 65,204,485\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inp, out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.06, clipnorm=0.5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=EPOCHS, steps_per_epoch=int(np.ceil(N_SAMPLES/BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(words, color_array):\n",
    "    # words is a list of words\n",
    "    # color_array is an array of numbers between 0 and 1 of length equal to words\n",
    "    cmap = matplotlib.cm.get_cmap('Reds')\n",
    "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
    "    colored_string = ''\n",
    "    for word, color in zip(words, color_array):\n",
    "        color = matplotlib.colors.rgb2hex(cmap(color)[:3])\n",
    "        colored_string += template.format(color, '&nbsp' + word + '&nbsp')\n",
    "    return colored_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(words, weights):\n",
    "    \"\"\"\n",
    "    words: list of words (string)\n",
    "    weights: list of corresponding weights\n",
    "    \"\"\"\n",
    "    weights_minmax = MinMaxScaler(feature_range=(0.2, 0.8)).fit_transform(np.array(weights).reshape(-1,1)).squeeze(axis=1)\n",
    "    s = colorize(words, weights_minmax)\n",
    "    display(HTML(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'reviews.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter 1-star or 5-star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['stars'].isin([1.0, 5.0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only `TEST_SIZE` samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 1000\n",
    "texts = df['text'].values[:TEST_SIZE]\n",
    "stars = df['stars'].values[:TEST_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(map(tokenizer.encode, texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = tf.keras.preprocessing.sequence.pad_sequences(texts, \n",
    "                                                      maxlen=PADDED_LEN, \n",
    "                                                      dtype='int64', \n",
    "                                                      padding='post', \n",
    "                                                      truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: only choose samples with high confidence (probability > 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = model.predict(np.array(texts), batch_size=500, verbose=1)\n",
    "# high_confidence_index = np.where(np.max(y, axis=1) > 0.99)\n",
    "# texts = texts[high_confidence_index]\n",
    "# stars = stars[high_confidence_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model = tf.keras.Model(model.input, tf.get_default_graph().get_tensor_by_name('attention_weights:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"barcode\"; style=\"color: black; background-color: #f96245\">&nbspthis&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #f03f2e\">&nbspreview&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #c3161b\">&nbspis&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fb694a\">&nbspin&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #f96346\">&nbspregards&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9272\">&nbspto&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca082\">&nbspour&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fb7757\">&nbspexperience&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #f4503a\">&nbspwatching&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca285\">&nbsp<UNK>&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9474\">&nbsp51&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc8f6f\">&nbspfebruary&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fdc5ae\">&nbsp5&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbfa7\">&nbsp2017&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fdcab5\">&nbspat&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fdc5ae\">&nbspthe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcb99f\">&nbspwestgate&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcc1a8\">&nbspin&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbca2\">&nbspthe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca588\">&nbsptheater&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbfa7\">&nbsp<UNK>&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcb89e\">&nbspwatch&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcb398\">&nbspthe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca486\">&nbspgame&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fb7252\">&nbspsomewhere&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #f5533b\">&nbspelse&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc8d6d\">&nbspto&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9474\">&nbspthose&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9373\">&nbspunfamiliar&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcaa8d\">&nbspwith&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca78b\">&nbspthe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9373\">&nbspbig&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc8262\">&nbspgame&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #f14432\">&nbspexperience&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca486\">&nbspat&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9c7d\">&nbspwestgate&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fdc6b0\">&nbspyou&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbfa7\">&nbsptypically&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca78b\">&nbspwould&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcad90\">&nbspget&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbca2\">&nbspin&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbfa7\">&nbspline&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcc3ab\">&nbspto&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbda4\">&nbspwatch&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcb99f\">&nbspthe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fdc5ae\">&nbsp<UNK>&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fdc6b0\">&nbspin&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbfa7\">&nbspthe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca78b\">&nbsptheater&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fb7353\">&nbspportion&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9070\">&nbspof&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9879\">&nbspthe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fb6c4c\">&nbsphotel&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc8262\">&nbsparound&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fb7c5c\">&nbsp8&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc8b6b\">&nbspam&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca98c\">&nbspon&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcc1a8\">&nbsp<UNK>&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcb89e\">&nbspsunday&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcb499\">&nbspthis&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcb398\">&nbspline&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbea5\">&nbspcan&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbba1\">&nbspget&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca588\">&nbspextremely&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9879\">&nbsplong&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca689\">&nbspyet&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9e80\">&nbspthe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc997a\">&nbspearlier&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fdc5ae\">&nbspyou&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcc4ad\">&nbspget&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fdc9b3\">&nbspin&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fdc7b2\">&nbspline&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fdc6b0\">&nbspyour&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbca2\">&nbspchoice&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbda4\">&nbspof&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca78b\">&nbspseating&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc997a\">&nbspsignificantly&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbea5\">&nbsp<UNK>&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcc3ab\">&nbspso&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbfa7\">&nbspafter&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcaa8d\">&nbspwaiting&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbba1\">&nbspin&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbfa7\">&nbspline&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbda4\">&nbspfor&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbda4\">&nbspa&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcb296\">&nbspfew&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcb499\">&nbsphours&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fcbca2\">&nbspwe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9e80\">&nbspwere&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9777\">&nbspnotified&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca082\">&nbspthe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9373\">&nbsplower&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fb7252\">&nbspportion&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc997a\">&nbspof&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fca689\">&nbspthe&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fc9373\">&nbsptheater&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #f5523a\">&nbspwas&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #f0402f\">&nbspreserved&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #fa6849\">&nbspfor&nbsp</span><span class=\"barcode\"; style=\"color: black; background-color: #bc141a\">&nbsppaid&nbsp</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_text = texts[i]\n",
    "a = visualize_model.predict(np.array([test_text]))\n",
    "a = np.squeeze(a, axis=0)\n",
    "a_normalized = np.sum(a, axis=1) / np.sum(a)\n",
    "visualize(tokenizer.decode(test_text), a_normalized)\n",
    "i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
